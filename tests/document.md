## These are the papers that will help on factchecking on graph knowledge.

[arxiv](https://arxiv.org/pdf/2406.03746) Efficient Knowledge Infusion via KG-LLM Alignment. 2024.06

Description
```
 In this paper, we leverage a
small set of labeled samples and a large-scale
corpus to efficiently construct domain-specific
knowledge graphs by an LLM, addressing the
issue of knowledge mismatch. Additionally, we
propose a three-stage KG-LLM alignment strategy to enhance the LLM’s capability to utilize
information from knowledge graphs.
```

[arxiv](https://arxiv.org/pdf/2406.02110) UniOQA: A Unified Framework for Knowledge Graph Question Answering with Large Language Model.

Description: 
```
we fine-tune an LLM to translate
questions into the Cypher query language (CQL), tackling issues associated with restricted semantic understanding and hallucinations.
Subsequently, we introduce the Entity and Relation Replacement
algorithm to ensure the executability of the generated CQL. Concurrently, to augment overall accuracy in question answering, we
further adapt the Retrieval-Augmented Generation (RAG) process
to the knowledge graph. 
```

[arxiv](https://arxiv.org/pdf/2406.02962) Docs2KG: Unified Knowledge Graph Construction from Heterogeneous Documents Assisted by Large Language Models. 2024.06
Description:
```
, we introduce Docs2KG,
a novel framework designed to extract multimodal information
from diverse and heterogeneous unstructured documents, 
```

[arxiv](https://arxiv.org/pdf/2310.02166) Large Language Models Meet Knowledge Graphs to Answer Factoid Questions. 2023.10
Description:
```
In this paper, we propose a method for exploring pre-trained Textto-Text Language Models enriched with additional information from Knowledge Graphs
for answering factoid questions. 

```
Note: they are using already exist dataset 




[EMNLP](https://arxiv.org/pdf/2310.11638) Systematic Assessment of Factual Knowledge in Large Language Models. 2023.10
Description:
```
This paper proposes a framework to systematically
assess the factual knowledge of LLMs by leveraging knowledge graphs (KGs). Our framework automatically generates a set of questions
and expected answers from the facts stored in a
given KG, and then evaluates the accuracy of
LLMs in answering these questions.
```


[EMNLP](https://arxiv.org/pdf/2310.02166) KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using Large Language Models. 2023.10
Description:
```
e KG-GPT, a multi-purpose framework leveraging LLMs for tasks employing
KGs. KG-GPT comprises three steps: Sentence
Segmentation, Graph Retrieval, and Inference,
each aimed at partitioning sentences, retrieving relevant graph components, and deriving
logical conclusions, respectively. We evaluate KG-GPT using KG-based fact verification
and KGQA benchmarks, with the model showing competitive and robust performance, even
outperforming several fully-supervised models.
```



[arxiv](https://arxiv.org/pdf/2309.00240) FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking. 2023.09

Description:
```
we propose combining the power of instruction-following language
models with external evidence retrieval to enhance fact-checking
performance.

Our approach involves leveraging search engines to
retrieve relevant evidence for a given input claim
```

[ACL2023](https://arxiv.org/pdf/2305.06590) FactKG: Fact Verification via Reasoning on Knowledge Graphs. 2023.05

Description:
```
To enable the community to better use KGs, we introduce a new
dataset, FACTKG: Fact Verification via Reasoning on Knowledge Graphs. It consists of
108k natural language claims with five types
of reasoning: One-hop, Conjunction, Existence, Multi-hop, and Negation. Furthermore,
FACTKG contains various linguistic patterns,
including colloquial style claims as well as
written style claims to increase practicality.
```

[arxiv](https://arxiv.org/pdf/2405.06524) Prompting Large Language Models with Knowledge Graphs for Question Answering Involving Long-tail Facts. 2024.05

Description:
```
 Since LLMs have probably seen the majority of factual question-answering datasets already,
to facilitate our analysis, we proposed a fully automatic pipeline for creating a benchmark that requires knowledge
of long-tail facts for answering the involved questions. Using this pipeline, we introduce the LTGen benchmark.
We evaluate state-of-the-art LLMs in different knowledge settings using the proposed benchmark. Our experiments
show that LLMs alone struggle with answering these questions, especially when the long-tail level is high or rich
knowledge is required.
```


[arxiv](https://arxiv.org/pdf/2404.06571) Building A Knowledge Graph to Enrich ChatGPT Responses in Manufacturing Service Discovery. 2024.04
Description:
```
 This research explores the potential of leveraging Knowledge
Graphs in conjunction with ChatGPT to streamline the process for prospective clients in identifying small
manufacturing enterprises. In this study, we propose a method that integrates bottom-up ontology with
advanced machine learning models to develop a Manufacturing Service Knowledge Graph from an array
of structured and unstructured data sources, including the digital footprints of small-scale manufacturers
throughout North America.



The dataset developed for this study, now publicly accessible, encompasses more than 13,000
manufacturers’ weblinks, manufacturing services, certifications, and location entity types. 
```